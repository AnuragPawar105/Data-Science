{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42ae75d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy                                    \n",
    "from spacy.lang.en import English                            \n",
    "nlp = spacy.load(\"en_core_web_sm\")                    \n",
    "import collections\n",
    "from typing import Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a615a745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 1\n",
    "def text2bow(words: List[str], dictionary: Dict[str, int]) -> List[Tuple[int, int]]:\n",
    "    word_frequences = collections.defaultdict(int)\n",
    "    for word in words:\n",
    "        if word not in dictionary:\n",
    "            dictionary[word] = len(dictionary)\n",
    "        word_frequences[dictionary[word]] += 1\n",
    "    return list(word_frequences.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "616bde99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " BOW Representation for a: \n",
      " [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]\n",
      "Input Text:\n",
      " Review 1: This movie is very scary and long.\n",
      "\n",
      "Dictionary: \n",
      " {'Review': 0, '1:': 1, 'This': 2, 'movie': 3, 'is': 4, 'very': 5, 'scary': 6, 'and': 7, 'long.': 8}\n"
     ]
    }
   ],
   "source": [
    "a=\"Review 1: This movie is very scary and long.\"\n",
    "b=\"Review 2: This movie is not scary and is slow.\"\n",
    "c=\"Review 3: This movie is spooky and good.\"\n",
    "adictionary= {}\n",
    "bdictionary= {}\n",
    "cdictionary= {}\n",
    "print('\\n BOW Representation for a: \\n', text2bow(a.split(), adictionary))\n",
    "print('Input Text:\\n',a)\n",
    "print('\\nDictionary: \\n',adictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "807df6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " BOW Representation for b: \n",
      " [(0, 1), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 1)]\n",
      "Input Text:\n",
      " Review 2: This movie is not scary and is slow.\n",
      "\n",
      "Dictionary: \n",
      " {'Review': 0, '2:': 1, 'This': 2, 'movie': 3, 'is': 4, 'not': 5, 'scary': 6, 'and': 7, 'slow.': 8}\n"
     ]
    }
   ],
   "source": [
    "print('\\n BOW Representation for b: \\n', text2bow(b.split(), bdictionary))\n",
    "print('Input Text:\\n',b)\n",
    "print('\\nDictionary: \\n',bdictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33a56eb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " BOW Representation for c: \n",
      " [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)]\n",
      "Input Text:\n",
      " Review 3: This movie is spooky and good.\n",
      "\n",
      "Dictionary: \n",
      " {'Review': 0, '3:': 1, 'This': 2, 'movie': 3, 'is': 4, 'spooky': 5, 'and': 6, 'good.': 7}\n"
     ]
    }
   ],
   "source": [
    "print('\\n BOW Representation for c: \\n', text2bow(c.split(), cdictionary))\n",
    "print('Input Text:\\n',c)\n",
    "print('\\nDictionary: \\n',cdictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0b4df4",
   "metadata": {},
   "source": [
    "#### a) BOW representation\n",
    "1. for a- Review(0,1), scary(6,1)\n",
    "2. for b- Review(0,1), scary(6,1)\n",
    "3. for c- Review(0,1), scary(word not present)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652c967c",
   "metadata": {},
   "source": [
    "#### b) Dictionary values\n",
    "1. for a- Review =0, scary=6\n",
    "2. for b- Review =0, scary=6\n",
    "3. for c- Review =0, scary=(word not present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "924aabb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey Siri\n"
     ]
    }
   ],
   "source": [
    "# TASK 2 a)\n",
    "from spacy.matcher import Matcher\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "matcher=Matcher(nlp.vocab)\n",
    "pattern=[{'lower':'hey'},{'lower':'siri'}]\n",
    "matcher.add('HEYSIRI',[pattern])\n",
    "doc=nlp('Hey, Siri! Hey Siri!')\n",
    "matches=matcher(doc)\n",
    "for match_id,start,end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "    span=doc[start:end]\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "147d5d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, Siri\n"
     ]
    }
   ],
   "source": [
    "# 2 b)\n",
    "from spacy.matcher import Matcher\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "matcher=Matcher(nlp.vocab)\n",
    "pattern=[{'lower':'hey'},{'is_punct':True},{'lower':'siri'}]\n",
    "matcher.add('HEYSIRI',[pattern])\n",
    "doc=nlp('Hey, Siri! Hey Siri!')\n",
    "matches=matcher(doc)\n",
    "for match_id,start,end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]\n",
    "    span=doc[start:end]\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c666177f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text :  apple \tVector:  True \t OOV:  True\n",
      "Text :  orange \tVector:  True \t OOV:  True\n",
      "Text :  pikkstn \tVector:  True \t OOV:  True\n",
      "Text :  German \tVector:  True \t OOV:  True\n"
     ]
    }
   ],
   "source": [
    "# TASK 3\n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "\n",
    "doc=nlp('apple orange pikkstn German')\n",
    "for token in doc:\n",
    "    print('Text : ',token.text,'\\tVector: ',token.has_vector,'\\t OOV: ',token.is_oov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b324aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sweet oranges\n"
     ]
    }
   ],
   "source": [
    "# TASK 4\n",
    "txt='Do not put rotten mangoes and sweet oranges together.'\n",
    "\n",
    "from spacy.matcher import PhraseMatcher                           \n",
    "nlp=spacy.load('en_core_web_sm')                              \n",
    "matcher=PhraseMatcher(nlp.vocab)\n",
    "term=['ROTTEN mangoes','sweet oranges']\n",
    "pattern=[nlp.make_doc(text) for text in term]\n",
    "matcher.add('TerminologyList',pattern)\n",
    "doc=nlp(txt)\n",
    "matches=matcher(doc)\n",
    "for match_id,start,end in matches:                             \n",
    "    span=doc[start:end]\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8bf7307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "Length of output vector :  (96,)\n",
      "\n",
      "Word vector representation : \n",
      " [-0.06573781  0.34356946 -0.33065927  0.0828037   1.3537043   2.028841\n",
      " -0.45235258  0.19368112  1.2412268  -1.6775186   0.01488355  0.4813134\n",
      " -1.0602243  -1.1236367   1.2962728  -1.2600684   1.3997769   1.7463315\n",
      " -0.36026517  0.6132093   0.2727727  -0.8195218   0.13840258  0.4460678\n",
      " -0.77039903 -0.6711768   0.8262315  -0.4665807  -0.51960653 -0.6145005\n",
      "  0.0505133  -0.51428145 -0.5847853  -0.6880101  -0.28734738 -0.9871149\n",
      " -1.1688107   0.5092508  -1.306536   -0.81702244 -0.08091132  0.42338413\n",
      " -0.11912183 -1.101825   -1.1702521  -0.61183274  0.9429907  -1.2650319\n",
      "  0.60604    -1.3219539   1.0244133   1.7270942   1.3285427  -0.500371\n",
      "  0.03123438  0.62746775  0.4628928  -0.49359262  1.1412562  -1.0653315\n",
      "  0.13612919  0.440745    1.5435817  -0.45034686  0.24856904 -0.7066307\n",
      "  1.0885928  -0.6219971   0.9163412  -0.677055    0.44630724  1.6822906\n",
      "  1.4854448  -0.2115066  -0.38538712 -1.5729198  -0.85097414  0.1366705\n",
      "  1.0358716   0.4824928  -0.24531719 -1.2484313   1.1187266   1.9735047\n",
      "  0.00526129 -0.35265073  0.57432157  0.30865774 -0.60618305  0.16552271\n",
      " -0.66783273 -1.087507    0.3536148   0.17064357 -0.58291876  0.03257972]\n",
      "prefer\n",
      "Length of output vector :  (96,)\n",
      "\n",
      "Word vector representation : \n",
      " [-1.4813951e-01 -2.6761371e-01 -5.9206104e-01  2.0073287e+00\n",
      "  8.8076121e-01  1.6360015e-02  7.5991660e-01  8.2863009e-01\n",
      "  6.9419071e-02  5.7006478e-03  3.8009167e-01  1.2934144e-01\n",
      "  1.1565382e-01  1.2962931e-01  8.9279556e-01  3.2847139e-01\n",
      " -5.6212443e-01  9.7068280e-02  7.4544054e-01 -7.3347974e-01\n",
      "  2.9324833e-01 -8.4798706e-01  7.0489451e-02 -2.1259421e-01\n",
      " -8.5842186e-01  9.8784852e-01 -2.9701900e-01 -6.5275902e-01\n",
      " -3.5265660e-01  4.5871116e-02 -8.1292224e-01 -4.4138372e-01\n",
      "  2.8861278e-01  5.5711746e-02 -9.1989529e-01 -1.1265435e+00\n",
      " -3.9958763e-01 -3.3302438e-01  2.3963382e+00  1.4369457e+00\n",
      " -5.0019264e-02  5.7935551e-02  9.7832531e-03  6.8604529e-01\n",
      "  7.3328078e-01 -3.1135830e-01 -4.3805271e-01  5.3087465e-02\n",
      "  4.0728945e-01 -5.5461407e-02  2.4219710e-01 -8.4027416e-01\n",
      " -4.5222196e-01 -6.0200191e-01 -5.2064413e-01 -5.5509543e-01\n",
      " -5.3749394e-01  1.0833538e+00  6.5684491e-01 -2.0811699e-01\n",
      " -2.0562059e-01  7.4169862e-01 -3.7418097e-01  2.9161641e-01\n",
      "  2.3070817e-01  1.7184833e-01 -1.4385326e+00 -1.0475776e+00\n",
      "  1.7837808e-01  2.2913545e-02 -6.4123929e-02 -2.8383031e-02\n",
      " -5.8394700e-01 -7.0994359e-01  3.5505283e-01 -3.2143980e-01\n",
      " -6.8857920e-01  1.6701552e-01 -4.4267616e-01 -2.3984078e-01\n",
      "  3.0814713e-01  2.4750099e-02 -5.5152267e-02 -1.0756354e-01\n",
      " -4.9009928e-01 -8.0314189e-01 -1.2910265e-01 -7.8190379e-02\n",
      " -1.2184476e+00  3.4058180e+00 -1.9478202e-03 -8.2747412e-01\n",
      " -3.1399667e-02  1.0619690e-01  1.3415750e+00 -3.0373150e-01]\n",
      "the\n",
      "Length of output vector :  (96,)\n",
      "\n",
      "Word vector representation : \n",
      " [-0.41507596  0.6040762   0.3495435  -0.20067962  0.15902871 -1.2854143\n",
      " -0.8267808   0.04841252  1.8430529   1.0688039  -0.312579    0.6385026\n",
      " -0.61563754 -0.1153381   1.8455572   0.51716995  2.4637392   0.18552026\n",
      "  0.41964847 -0.5912236  -0.86367    -0.7808994  -0.1438894   0.6311824\n",
      " -0.5940453  -1.1125991  -0.470824   -0.77882993  0.19893026  0.22782868\n",
      "  1.3183049  -0.36079872  0.32274386  0.08369911  1.3574529   1.3517244\n",
      " -0.8146358  -0.6999086  -0.7432875  -0.7380463   0.8722851  -1.6574209\n",
      "  1.6984841  -0.6304618   0.11479789 -0.91995656 -0.8386962  -0.10077912\n",
      " -0.7220528  -0.22950163 -0.6801956  -0.65611625  0.43125126 -0.68603814\n",
      " -0.5478005  -0.5289711  -0.62100947  0.91922826  0.2771902   0.16156435\n",
      " -1.254341    1.0219886   0.561022   -0.2497426   0.7308371  -0.6924583\n",
      "  0.6950296   0.33990902 -0.7505448  -0.46954373 -0.1791274  -0.9831102\n",
      " -0.42925367  0.919256   -1.2027421  -1.1286519   1.387554   -0.48682958\n",
      " -0.2875861   0.07982042 -1.0629318  -0.39238867 -0.22684997 -0.41302878\n",
      " -0.38970968  0.761467   -0.8814099   1.1809459   0.28941858  1.3576038\n",
      "  0.02331407  1.829487   -1.0420256   0.49904293  0.07788761  0.20054778]\n",
      "morning\n",
      "Length of output vector :  (96,)\n",
      "\n",
      "Word vector representation : \n",
      " [ 0.06413983  0.38541207  1.20685     0.4311617   1.2290244  -0.33127353\n",
      " -0.16384894  0.25209734  0.5992079   0.06535822  0.22242859 -1.5573704\n",
      "  0.22867851  0.14687373  0.5994947  -0.31759244  0.11512005 -0.02401716\n",
      "  1.5409775   0.5833105   0.5310116  -0.4210304  -0.36591268  0.45853746\n",
      "  0.33631498 -0.11574838 -1.2853689  -0.63279307  0.14904067 -0.50869626\n",
      "  1.4831327  -0.12808388 -0.27388686  0.1892512   1.2261683   0.72315335\n",
      "  0.09443593 -0.6901243  -0.41846102  0.31178677 -1.3447284  -0.72976816\n",
      "  0.17496249 -0.24490055 -0.0725891   1.4196081  -0.5796263  -0.45211986\n",
      "  0.57368183 -0.49194956 -0.0604111   0.46472228 -0.75657815 -1.0027243\n",
      "  0.38447943 -0.5035488   0.0549864   0.1685025   0.1918163  -0.50706464\n",
      "  0.05325069 -0.4554767  -0.11388862  0.4075879   0.0073912   0.8338722\n",
      "  1.0780506  -0.8131534  -0.6634054  -0.54004055  0.04876997 -0.23267925\n",
      " -0.6288402  -0.19953394 -0.04780579 -0.8425254  -0.8344764  -0.04012573\n",
      "  0.2817984  -1.455622    0.36638993  0.37593096  0.58130586  1.2051245\n",
      " -0.16432889 -0.30993873 -0.5933747  -0.9333577  -0.7058327  -0.31934136\n",
      " -0.37847912 -0.05457399  0.8582653   0.3409618  -0.5441731   0.3063135 ]\n",
      "flight\n",
      "Length of output vector :  (96,)\n",
      "\n",
      "Word vector representation : \n",
      " [-0.09036812  1.0385269   0.31658447  0.4485303   0.31561932 -0.5981399\n",
      " -0.17256641 -0.6339485   0.20791398  0.6407775  -0.91413707 -0.13455163\n",
      "  0.636768   -0.23802868  0.5440414   0.11527729 -0.2962646   0.26815557\n",
      " -0.48613173  0.4794222  -0.21168382  0.19628236  0.36195135  0.48577037\n",
      "  0.6253845  -0.1977327  -0.3779457  -0.6427568   0.09227502 -0.16335267\n",
      "  0.76931477 -0.9167789   0.376282    0.06524286 -0.19477828  0.05073746\n",
      " -0.26177642 -0.42858434 -0.01852793  0.20608947 -0.74854374 -0.66212153\n",
      "  0.20471582  0.811574   -0.7541647  -0.26430658 -0.33861986 -0.14964479\n",
      "  1.2942221  -0.37427774 -0.24595371 -0.4474309  -0.30047083 -0.17539746\n",
      " -0.5864091   0.06098372 -0.35809773  0.224635   -0.6155557  -0.11489233\n",
      "  0.29390132  0.01393956  0.35283536 -0.7482529  -0.46276528  0.24825177\n",
      " -0.33851993 -0.2789786  -0.22421798  0.21680059  0.10364059 -0.71906066\n",
      "  0.12679888 -0.22641349  0.64705795 -0.07809806 -0.75692165  1.0999833\n",
      "  0.31356105 -1.2497472   1.179651   -0.6381695   0.48224095 -0.0547393\n",
      "  0.69685256 -0.19100296  0.19653122 -1.0759368  -0.05947289 -0.73815215\n",
      " -0.98463005  0.4765255  -0.13521303  0.3378131   1.1781936  -0.04604666]\n",
      "through\n",
      "Length of output vector :  (96,)\n",
      "\n",
      "Word vector representation : \n",
      " [ 0.80070215  0.398761   -0.42413628 -0.21142362 -1.6019455  -0.77920824\n",
      " -0.38177374  0.6728015   0.6448051  -0.5640906   0.19078417  1.3154465\n",
      "  0.8887087  -0.24018767  0.84551513 -0.3812151   0.56349343  0.5413499\n",
      " -0.3671332  -0.5060743   0.28937924 -0.7218124  -0.1027748   0.34486848\n",
      " -1.0777464  -0.33200324  0.02194832  0.62190235  0.999821    0.32484815\n",
      "  1.4007392   0.65213585  0.27320725 -0.83155787 -0.5271624  -0.8481008\n",
      "  2.4508572  -0.77268976  0.03889352 -0.13160041 -0.90866876 -1.3416644\n",
      "  0.07415256 -0.30084723 -0.29758602 -0.62054706 -1.3007972  -1.0396242\n",
      "  0.26990664  0.36534333 -0.6617764  -1.0362064  -0.6404452   2.080657\n",
      "  0.5979638  -0.7011648  -0.36224693 -0.26730976  0.07518129 -0.7388945\n",
      "  0.1488809   0.17064026  0.41952142  0.12248527 -0.03425927  1.2576662\n",
      " -0.88465446 -0.444575   -0.45821923 -0.08443776 -0.43215913  0.37915188\n",
      "  1.0236447   0.86440325  1.3451195   1.116738    0.4303401  -0.354598\n",
      "  0.41119814 -0.2733184   0.8169113   0.1593062  -0.22511041 -0.5160285\n",
      " -0.2617602  -0.9212406  -0.90450287 -1.207618    0.02735189  0.10036233\n",
      " -1.2430325   0.34258947 -0.06948951 -0.21369968  1.2664676   1.8969053 ]\n",
      "Denmark\n",
      "Length of output vector :  (96,)\n",
      "\n",
      "Word vector representation : \n",
      " [-0.2004771   2.139937   -0.70581937  0.38230997  0.09044279 -0.8517021\n",
      " -0.6867304  -0.39717758 -0.5642976   1.0552008  -0.09990156  0.4600368\n",
      " -0.14100227  0.1847501   0.17331842  0.41164026 -1.0241499   0.9502887\n",
      "  0.4854349  -0.1170246   0.12120646  0.06002566 -0.56184685  1.6518021\n",
      "  0.51199865 -0.17439978 -1.0001459  -1.2934655   0.54632974 -0.8142538\n",
      "  1.1279402  -0.75172853  0.10675573  0.9898789   1.186308   -2.610289\n",
      " -0.31466523  0.62634796 -1.3309898   1.088281   -0.07900606 -0.7328501\n",
      "  0.36984295  0.40037614 -0.17302474 -0.7784314  -0.58096373 -0.30835277\n",
      "  0.79803187 -0.7341461  -0.72435284  1.6619899   0.28698656 -0.24436834\n",
      "  1.0193725  -0.5964082  -0.6410061   1.0623158  -0.10366905 -0.49634337\n",
      " -0.41985774  0.5688313  -0.13427675 -1.2171836   1.3858764  -0.12423129\n",
      " -0.7578216  -1.2748365   0.71280867 -1.0844731   0.52021974 -0.7323321\n",
      " -0.41292953  1.1002673   0.8179137  -0.06436124 -1.453013    0.9940683\n",
      "  0.13895303 -0.83635795  0.6287901   0.46145457  0.51341593  0.12506993\n",
      " -0.55108106 -0.22268255 -0.0999679   0.35693273  0.06574214  0.05174553\n",
      " -0.5090709   0.44766927 -0.09607074  0.3480175   0.28784707 -0.27301502]\n"
     ]
    }
   ],
   "source": [
    "# TASK 5\n",
    "sen='I prefer the morning flight through Denmark'\n",
    "\n",
    "doc=nlp(sen)\n",
    "for word in doc:\n",
    "    print(word)\n",
    "    print('Length of output vector : ',word.vector.shape)                    \n",
    "    print('\\nWord vector representation : \\n',word.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "693a6905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  rotten \tVector:  True \tOOV:  True\n",
      "Text:  oranges \tVector:  True \tOOV:  True\n"
     ]
    }
   ],
   "source": [
    "# TASK 6 a)\n",
    "doc=nlp(txt)\n",
    "for word in doc:\n",
    "    if (word.text ==  'rotten' or word.text == 'oranges'):\n",
    "        print('Text: ',word.text,'\\tVector: ',word.has_vector,'\\tOOV: ',word.is_oov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f5742fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity value between mangoes and oranges :\n",
      " \n",
      "mangoes oranges 0.7203169465065002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anura\\AppData\\Local\\Temp/ipykernel_38928/61321982.py:6: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(token1.text,token2.text,token1.similarity(token2))\n"
     ]
    }
   ],
   "source": [
    "#6 b)\n",
    "print('Similarity value between mangoes and oranges :\\n ')\n",
    "for token1 in doc:\n",
    "    for token2 in doc:\n",
    "        if token1.text == 'mangoes' and token2.text == 'oranges':\n",
    "            print(token1.text,token2.text,token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca6858dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity value between sweet and oranges :\n",
      " \n",
      "sweet oranges -0.038050491362810135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anura\\AppData\\Local\\Temp/ipykernel_38928/2596546479.py:7: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(token1.text,token2.text,token2.similarity(token1))\n"
     ]
    }
   ],
   "source": [
    "#6 c)\n",
    "\n",
    "print('Similarity value between sweet and oranges :\\n ')\n",
    "for token1 in doc:\n",
    "    for token2 in doc:\n",
    "        if token1.text=='sweet' and token2.text=='oranges':\n",
    "            print(token1.text,token2.text,token2.similarity(token1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ac388e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
